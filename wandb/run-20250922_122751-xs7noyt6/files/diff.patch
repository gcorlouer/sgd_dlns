diff --git a/scripts/train.py b/scripts/train.py
index 099a78f..73cc7f8 100644
--- a/scripts/train.py
+++ b/scripts/train.py
@@ -9,6 +9,12 @@ from torch import nn
 from teacher import *
 from models import *
 from pathlib import Path
+import wandb
+
+wandb.init(
+    project="sgd-dln",
+    entity="geeom"   # your personal username
+)
 
 # Code training loop class with SGD
 class Trainer():
@@ -78,6 +84,11 @@ class Trainer():
             train_loss = self.epoch_training_loop(train_loader)
             self.train_losses.append(train_loss)
             self.test_losses.append(self.evaluate(test_loader).item())
+            wandb.log({
+                        "train_loss": train_loss,
+                        "test_loss": self.evaluate(test_loader).item(),
+                        "epoch": i
+                    })
 
     def evaluate(self, test_loader: DataLoader):
         test_loss = 0
@@ -101,7 +112,7 @@ if __name__ == '__main__':
     rank = 4
     whiten_inputs = True
     progression = 'linear'
-    noise_std = 0
+    noise_std = 1
     num_hidden_layers = 3
     gamma = 2.5  # \sigma^2 = w^(-gamma)
     lr = 1e-4
@@ -109,7 +120,7 @@ if __name__ == '__main__':
     max_singular_value = 100
     decay_rate = 10
     n_samples = 20
-    num_epochs = 100000
+    num_epochs = 10000
     teacher = Teacher(output_dim=output_dim, input_dim=input_dim, rank=rank,
                       max_singular_value=max_singular_value,
                       min_singular_value=1e-12,
@@ -138,4 +149,5 @@ if __name__ == '__main__':
     plt.plot(iterations, test_loss, label="Test loss")
     plt.legend()
     plt.savefig(fpath)
-    plt.show()
\ No newline at end of file
+    plt.show()
+    wandb.log({"loss_curve": wandb.Image(plt)})
